# ==============================================================================
# Application Deployment Pipeline - AWS ECS Fargate
#
# This workflow deploys application updates to an existing ECS Fargate cluster.
# It is triggered automatically after a successful CI build on the main branch.
# Its primary job is to run `terraform apply` with the new Docker image tags.
# ==============================================================================

name: Deploy Application to ECS (app-deploy-ecs)

on:
  workflow_run:
    workflows: ["CI/CD Pipeline"]
    branches: [main]
    types:
      - completed

  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'dev'
        type: choice
        options: [dev, staging, production]
      image_tag:
        description: 'Docker image tag (leave empty for latest from main)'
        required: false
        type: string

concurrency:
  group: deploy-app-ecs-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

permissions:
  id-token: write  # Required for OIDC authentication with AWS
  contents: read   # Required to checkout repositories

jobs:
  check-changes:
    name: Check if deployment needed
    runs-on: ubuntu-latest
    outputs:
      should_deploy: ${{ steps.set-output.outputs.should_deploy }}
    steps:
      - name: Checkout code to access workflow_run commit
        if: github.event_name == 'workflow_run'
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha }}
          fetch-depth: 0  # Fetch full history for proper diff comparison
      
      - name: Get parent commit
        if: github.event_name == 'workflow_run'
        id: parent
        run: |
          PARENT=$(git rev-parse ${{ github.event.workflow_run.head_sha }}^ 2>/dev/null || echo "")
          if [ -z "$PARENT" ]; then
            # If no parent (first commit), compare against base branch
            PARENT="${{ github.event.workflow_run.head_branch || 'main' }}"
          fi
          echo "parent=$PARENT" >> $GITHUB_OUTPUT
      
      - name: Check for application code changes
        if: github.event_name == 'workflow_run'
        uses: dorny/paths-filter@v2
        id: filter
        with:
          base: ${{ steps.parent.outputs.parent }}
          list-files: shell
          filters: |
            backend:
              - 'backend/**'
            frontend:
              - 'frontend/**'
      
      - name: Set should_deploy output
        id: set-output
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual dispatch detected - deploying"
            echo "should_deploy=true" >> $GITHUB_OUTPUT
          else
            SHOULD_DEPLOY="${{ steps.filter.outputs.backend || steps.filter.outputs.frontend }}"
            echo "should_deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
          fi

  plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    needs: check-changes
    permissions:
      id-token: write  # Required for OIDC authentication with AWS
      contents: read   # Required to checkout repositories
    if: |
      (github.event_name == 'workflow_dispatch') ||
      (github.event_name == 'workflow_run' && 
       github.event.workflow_run.conclusion == 'success' && 
       needs.check-changes.outputs.should_deploy == 'true')

    outputs:
      tf_plan_exitcode: ${{ steps.plan.outputs.exitcode }}
      environment: ${{ steps.vars.outputs.environment }}
      image_tag: ${{ steps.vars.outputs.image_tag }}
      tf_path: ${{ steps.vars.outputs.tf_path }}

    steps:
      - name: Checkout DEVOPS repository
        uses: actions/checkout@v4
        with:
          repository: ${{ secrets.DEVOPS_REPO_NAME || 'orshalit/DEVOPS' }} # DEVOPS repository (owner/repo-name)
          path: 'DEVOPS'
          ssh-key: ${{ secrets.DEVOPS_REPO_KEY }}

      - name: Download build version from CI workflow
        if: |
          github.event_name == 'workflow_run' &&
          github.event.workflow_run.conclusion == 'success'
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: build-version
          path: build-metadata
          run-id: ${{ github.event.workflow_run.id }}

      - name: Set up environment variables
        id: vars
        run: |
          ENV="${{ github.event.inputs.environment || 'dev' }}"
          echo "environment=$ENV" >> $GITHUB_OUTPUT
          echo "tf_path=DEVOPS/live/$ENV/04-ecs-fargate" >> $GITHUB_OUTPUT

          if [ -n "${{ github.event.inputs.image_tag }}" ]; then
            VERSION="${{ github.event.inputs.image_tag }}"
            echo "::notice::Using provided image tag: ${VERSION}"
          elif [ "${{ github.event_name }}" = "workflow_run" ] && [ -f "build-metadata/build-version.txt" ]; then
            VERSION="$(cat build-metadata/build-version.txt)"
            echo "::notice::Using build version from CI workflow: ${VERSION}"
          else
            # Fall back to commit SHA if artifact not available
            # This can happen if:
            # - Manual workflow_dispatch trigger
            # - CI workflow failed before creating artifact
            # - Artifact expired or not found
            VERSION="${GITHUB_SHA}"
            echo "::notice::Using commit SHA as version: ${VERSION}"
          fi

          echo "image_tag=$VERSION" >> $GITHUB_OUTPUT
          
          echo "::notice::Environment: $ENV"
          echo "::notice::Image Tag (version): $VERSION"
          echo "::notice::Terraform Path: DEVOPS/live/$ENV/04-ecs-fargate"

      - name: Debug GitHub context
        run: |
          echo "repository: $GITHUB_REPOSITORY"
          echo "ref:        $GITHUB_REF"
          echo "event_name: $GITHUB_EVENT_NAME"

      - name: Debug AWS role and region
        run: |
          echo "Has AWS_ROLE_ARN: $([ -n \"$AWS_ROLE_ARN\" ] && echo yes || echo no)"
          echo "AWS_ROLE_ARN length: ${#AWS_ROLE_ARN}"
          echo "AWS_REGION: $AWS_REGION"
        env:
          AWS_ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}
          AWS_REGION: ${{ secrets.AWS_REGION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION }}
          role-session-name: GitHubActions-ECS-Plan-${{ github.run_id }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        id: init
        run: terraform -chdir=${{ steps.vars.outputs.tf_path }} init

      - name: Generate service image tag overrides
        id: override
        run: |
          cat > ${{ steps.vars.outputs.tf_path }}/ci-service-tags.auto.tfvars <<EOF
          service_image_tags = {
            api_single = "${{ steps.vars.outputs.image_tag }}"
            api        = "${{ steps.vars.outputs.image_tag }}"
            frontend   = "${{ steps.vars.outputs.image_tag }}"
          }
          EOF

      - name: Terraform Plan
        id: plan
        run: |
          EXTRA_ARGS=""
          if [ -f "${{ steps.vars.outputs.tf_path }}/services.generated.tfvars" ]; then
            EXTRA_ARGS="$EXTRA_ARGS -var-file=services.generated.tfvars"
          fi
          terraform -chdir=${{ steps.vars.outputs.tf_path }} plan \
            -no-color \
            -out=tfplan \
            $EXTRA_ARGS \
            -var="terraform_backend_bucket_name=devops-project-terraform"
        continue-on-error: true

      - name: Add Plan to Summary
        if: steps.plan.outputs.exitcode == 0
        run: |
          echo "## Terraform Plan" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          terraform -chdir=${{ steps.vars.outputs.tf_path }} show -no-color tfplan >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload Plan Artifact
        uses: actions/upload-artifact@v4
        with:
          name: tfplan-${{ steps.vars.outputs.environment }}
          path: ${{ steps.vars.outputs.tf_path }}/tfplan

  apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: plan
    permissions:
      id-token: write  # Required for OIDC authentication with AWS
      contents: read   # Required to checkout repositories
    if: needs.plan.outputs.tf_plan_exitcode == 0

    environment:
      name: ${{ needs.plan.outputs.environment }}
      url: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}

    steps:
      - name: Checkout DEVOPS repository
        uses: actions/checkout@v4
        with:
          repository: ${{ secrets.DEVOPS_REPO_NAME || 'orshalit/DEVOPS' }} # DEVOPS repository (owner/repo-name)
          path: 'DEVOPS'
          ssh-key: ${{ secrets.DEVOPS_REPO_KEY }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION }}
          role-session-name: GitHubActions-ECS-Apply-${{ github.run_id }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Download Plan Artifact
        uses: actions/download-artifact@v4
        with:
          name: tfplan-${{ needs.plan.outputs.environment }}
          path: ${{ needs.plan.outputs.tf_path }}
      
      - name: Terraform Init
        run: terraform -chdir=${{ needs.plan.outputs.tf_path }} init

      - name: Save current service image tags for rollback
        id: save_current_tags
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          echo "::notice::Saving current service image tags for potential rollback..."
          
          # Get current image tags from Terraform state
          # We need to check the current state before applying
          CURRENT_TAGS=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} show -json 2>/dev/null | jq -r '
            .values.root_module.resources[]? | 
            select(.type == "aws_ecs_service") | 
            .values.task_definition | 
            split("/") | 
            .[-1] | 
            split(":") | 
            .[-1]
          ' | head -1 || echo "")
          
          # Also try to get from outputs if available
          if [ -z "$CURRENT_TAGS" ]; then
            # Try to get from ECS services directly
            CLUSTER_NAME=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -raw ecs_cluster_name 2>/dev/null || echo "")
            if [ -n "$CLUSTER_NAME" ]; then
              SERVICE_NAMES_JSON=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json service_names 2>/dev/null || echo "{}")
              if [ "$SERVICE_NAMES_JSON" != "{}" ]; then
                # Get first service to check current image
                FIRST_SERVICE=$(echo "$SERVICE_NAMES_JSON" | jq -r 'to_entries[0].value' 2>/dev/null || echo "")
                if [ -n "$FIRST_SERVICE" ]; then
                  CURRENT_TASK_DEF=$(aws ecs describe-services \
                    --cluster "$CLUSTER_NAME" \
                    --services "$FIRST_SERVICE" \
                    --region ${AWS_REGION} \
                    --query 'services[0].taskDefinition' \
                    --output text 2>/dev/null || echo "")
                  if [ -n "$CURRENT_TASK_DEF" ]; then
                    CURRENT_TAGS=$(aws ecs describe-task-definition \
                      --task-definition "$CURRENT_TASK_DEF" \
                      --region ${AWS_REGION} \
                      --query 'taskDefinition.containerDefinitions[0].image' \
                      --output text 2>/dev/null | sed 's/.*://' || echo "")
                  fi
                fi
              fi
            fi
          fi
          
          # Save current tags to output for rollback
          if [ -n "$CURRENT_TAGS" ] && [ "$CURRENT_TAGS" != "null" ]; then
            echo "previous_image_tag=$CURRENT_TAGS" >> $GITHUB_OUTPUT
            echo "::notice::Saved previous image tag: $CURRENT_TAGS"
          else
            echo "previous_image_tag=" >> $GITHUB_OUTPUT
            echo "::warning::Could not determine previous image tag. Rollback may not be possible."
          fi

      - name: Terraform Apply
        id: apply
        run: terraform -chdir=${{ needs.plan.outputs.tf_path }} apply -auto-approve tfplan

      - name: Diagnose ECS Services Before Verification
        id: diagnose
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        continue-on-error: true
        run: |
          CLUSTER_NAME=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -raw ecs_cluster_name)
          SERVICE_NAMES_JSON=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json service_names)
          SERVICES=$(echo "$SERVICE_NAMES_JSON" | jq -r 'to_entries[] | .value')

          echo "::group::ECS Service Diagnostics"
          for service in $SERVICES; do
            echo ""
            echo "=== Service: $service ==="
            
            # Get service status
            SERVICE_INFO=$(aws ecs describe-services \
              --cluster "$CLUSTER_NAME" \
              --services "$service" \
              --region ${AWS_REGION} \
              --output json)
            
            DESIRED=$(echo "$SERVICE_INFO" | jq -r '.services[0].desiredCount')
            RUNNING=$(echo "$SERVICE_INFO" | jq -r '.services[0].runningCount')
            PENDING=$(echo "$SERVICE_INFO" | jq -r '.services[0].pendingCount')
            
            echo "Desired: $DESIRED | Running: $RUNNING | Pending: $PENDING"
            
            # Check recent events
            echo "Recent Events:"
            echo "$SERVICE_INFO" | jq -r '.services[0].events[:3] | .[] | "  [\(.createdAt)] \(.message)"'
            
            # Check stopped tasks
            STOPPED_TASKS=$(aws ecs list-tasks \
              --cluster "$CLUSTER_NAME" \
              --service-name "$service" \
              --desired-status STOPPED \
              --region ${AWS_REGION} \
              --max-items 3 \
              --output json | jq -r '.taskArns[]' || echo "")
            
            if [ -n "$STOPPED_TASKS" ]; then
              echo "Stopped Tasks Found:"
              for task_arn in $STOPPED_TASKS; do
                TASK_INFO=$(aws ecs describe-tasks \
                  --cluster "$CLUSTER_NAME" \
                  --tasks "$task_arn" \
                  --region ${AWS_REGION} \
                  --output json)
                
                STOP_CODE=$(echo "$TASK_INFO" | jq -r '.tasks[0].stopCode // "unknown"')
                STOP_REASON=$(echo "$TASK_INFO" | jq -r '.tasks[0].stoppedReason // "unknown"')
                EXIT_CODE=$(echo "$TASK_INFO" | jq -r '.tasks[0].containers[0].exitCode // "N/A"')
                
                echo "  Task: $(basename $task_arn)"
                echo "    Stop Code: $STOP_CODE"
                echo "    Stop Reason: $STOP_REASON"
                echo "    Exit Code: $EXIT_CODE"
              done
            fi
            
            # Check target group health
            TASK_DEF_ARN=$(echo "$SERVICE_INFO" | jq -r '.services[0].taskDefinition // empty')
            if [ -n "$TASK_DEF_ARN" ]; then
              # Get load balancer info
              LB_INFO=$(echo "$SERVICE_INFO" | jq -r '.services[0].loadBalancers[0] // empty')
              if [ -n "$LB_INFO" ] && [ "$LB_INFO" != "null" ]; then
                TG_ARN=$(echo "$LB_INFO" | jq -r '.targetGroupArn // empty')
                if [ -n "$TG_ARN" ]; then
                  echo "Target Group Health:"
                  TG_HEALTH=$(aws elbv2 describe-target-health \
                    --target-group-arn "$TG_ARN" \
                    --region ${AWS_REGION} \
                    --output json 2>/dev/null || echo "{}")
                  
                  HEALTHY=$(echo "$TG_HEALTH" | jq -r '[.TargetHealthDescriptions[] | select(.TargetHealth.State == "healthy")] | length')
                  UNHEALTHY=$(echo "$TG_HEALTH" | jq -r '[.TargetHealthDescriptions[] | select(.TargetHealth.State != "healthy")] | length')
                  
                  echo "  Healthy: $HEALTHY | Unhealthy: $UNHEALTHY"
                  
                  if [ "$UNHEALTHY" -gt 0 ]; then
                    echo "  Unhealthy Targets:"
                    echo "$TG_HEALTH" | jq -r '.TargetHealthDescriptions[] | select(.TargetHealth.State != "healthy") | "    \(.Target.Id): \(.TargetHealth.State) - \(.TargetHealth.Reason // "N/A")"'
                  fi
                fi
              fi
            fi
          done
          echo "::endgroup::"

      - name: Verify ECS Service Stability
        id: verify
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          CLUSTER_NAME=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -raw ecs_cluster_name)
          SERVICE_NAMES_JSON=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json service_names)
          SERVICES=$(echo "$SERVICE_NAMES_JSON" | jq -r 'to_entries[] | .value')

          echo "::notice::Waiting for services to become stable..."
          aws ecs wait services-stable \
            --region ${AWS_REGION} \
            --cluster $CLUSTER_NAME \
            --services $SERVICES
          
          echo "âœ… Services are stable."

      - name: Verify Load Balancer Configuration
        if: success()
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        continue-on-error: true
        run: |
          echo "::group::Verifying Load Balancer and Target Group Associations..."
          
          # Get ALB information from Terraform outputs
          ALB_DNS_JSON=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json alb_dns_names 2>/dev/null || echo "{}")
          
          if [ "$ALB_DNS_JSON" != "{}" ]; then
            echo "ALBs found:"
            echo "$ALB_DNS_JSON" | jq -r 'to_entries[] | "  \(.key): \(.value)"'
            
            # Check each ALB for listeners and rules
            for alb_name in $(echo "$ALB_DNS_JSON" | jq -r 'keys[]'); do
              ALB_DNS=$(echo "$ALB_DNS_JSON" | jq -r --arg k "$alb_name" '.[$k]')
              
              # Get ALB ARN
              ALB_ARN=$(aws elbv2 describe-load-balancers \
                --region ${AWS_REGION} \
                --query "LoadBalancers[?DNSName=='$ALB_DNS'].LoadBalancerArn" \
                --output text 2>/dev/null || echo "")
              
              if [ -n "$ALB_ARN" ] && [ "$ALB_ARN" != "None" ]; then
                echo ""
                echo "=== ALB: $alb_name ==="
                
                # Check listeners
                LISTENERS=$(aws elbv2 describe-listeners \
                  --load-balancer-arn "$ALB_ARN" \
                  --region ${AWS_REGION} \
                  --output json 2>/dev/null || echo "{}")
                
                LISTENER_COUNT=$(echo "$LISTENERS" | jq -r '.Listeners | length')
                echo "Listeners: $LISTENER_COUNT"
                
                if [ "$LISTENER_COUNT" -eq 0 ]; then
                  echo "âš ï¸  No listeners found for this ALB"
                else
                  # Check listener rules
                  for listener_arn in $(echo "$LISTENERS" | jq -r '.Listeners[].ListenerArn'); do
                    RULES=$(aws elbv2 describe-rules \
                      --listener-arn "$listener_arn" \
                      --region ${AWS_REGION} \
                      --output json 2>/dev/null || echo "{}")
                    
                    RULE_COUNT=$(echo "$RULES" | jq -r '.Rules | length')
                    echo "  Listener $listener_arn: $RULE_COUNT rules"
                    
                    # Check if rules forward to target groups
                    TARGET_GROUPS=$(echo "$RULES" | jq -r '.Rules[] | select(.Actions[].Type == "forward") | .Actions[].TargetGroupArn // empty' | sort -u)
                    
                    if [ -n "$TARGET_GROUPS" ]; then
                      echo "  Target groups associated:"
                      for tg_arn in $TARGET_GROUPS; do
                        TG_NAME=$(aws elbv2 describe-target-groups \
                          --target-group-arns "$tg_arn" \
                          --region ${AWS_REGION} \
                          --query 'TargetGroups[0].TargetGroupName' \
                          --output text 2>/dev/null || echo "unknown")
                        
                        HEALTH=$(aws elbv2 describe-target-health \
                          --target-group-arn "$tg_arn" \
                          --region ${AWS_REGION} \
                          --output json 2>/dev/null || echo "{}")
                        
                        HEALTHY=$(echo "$HEALTH" | jq -r '[.TargetHealthDescriptions[]? | select(.TargetHealth.State == "healthy")] | length')
                        TOTAL=$(echo "$HEALTH" | jq -r '.TargetHealthDescriptions | length')
                        
                        echo "    $TG_NAME: $HEALTHY/$TOTAL healthy"
                      done
                    fi
                  done
                fi
              fi
            done
          else
            echo "âš ï¸  Could not retrieve ALB information from Terraform outputs"
          fi
          
          echo "::endgroup::"

      - name: Verify Service Discovery and CloudWatch Logs
        if: success()
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          NAMESPACE_ID=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -raw service_discovery_namespace_id)
          LOG_GROUPS_JSON=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json log_group_names)

          echo "::group::Verifying Service Discovery..."
          aws servicediscovery discover-instances \
            --region ${AWS_REGION} \
            --namespace-name $(aws servicediscovery get-namespace --id $NAMESPACE_ID --query 'Namespace.Name' --output text) \
            --service-name ${{ needs.plan.outputs.environment }}-api-service
          echo "âœ… Service discovery for api service is resolving."
          echo "::endgroup::"

          echo "::group::Checking CloudWatch Logs for Errors..."
          for name in $(echo "$LOG_GROUPS_JSON" | jq -r 'keys[]'); do
            GROUP=$(echo "$LOG_GROUPS_JSON" | jq -r --arg k "$name" '.[$k]')
            echo ""
            echo "=== Log Group: $GROUP ==="
            
            # Check if log group exists
            if ! aws logs describe-log-groups \
              --log-group-name-prefix "$GROUP" \
              --region ${AWS_REGION} \
              --query "logGroups[?logGroupName=='$GROUP'].logGroupName" \
              --output text | grep -q "$GROUP"; then
              echo "âš ï¸  Log group does not exist yet"
              continue
            fi
            
            # Get most recent log stream
            STREAM=$(aws logs describe-log-streams \
              --log-group-name "$GROUP" \
              --order-by LastEventTime \
              --descending \
              --max-items 1 \
              --region ${AWS_REGION} \
              --query 'logStreams[0].logStreamName' \
              --output text 2>/dev/null || echo "")
            
            if [ -z "$STREAM" ] || [ "$STREAM" = "None" ]; then
              echo "âš ï¸  No log streams found"
              continue
            fi
            
            echo "Most recent stream: $STREAM"
            
            # Get last 20 log events
            LOGS=$(aws logs get-log-events \
              --log-group-name "$GROUP" \
              --log-stream-name "$STREAM" \
              --limit 20 \
              --region ${AWS_REGION} \
              --output json 2>/dev/null || echo "{}")
            
            # Check for errors
            ERROR_COUNT=$(echo "$LOGS" | jq -r '[.events[]? | select(.message | test("(?i)(error|exception|fatal|failed|panic)"))] | length' || echo "0")
            
            if [ "$ERROR_COUNT" -gt 0 ]; then
              echo "âŒ Found $ERROR_COUNT error(s) in recent logs:"
              echo "$LOGS" | jq -r '.events[]? | select(.message | test("(?i)(error|exception|fatal|failed|panic)")) | "  [\(.timestamp | tonumber / 1000 | strftime("%Y-%m-%d %H:%M:%S"))] \(.message)"' | head -5
            else
              echo "âœ… No errors in recent logs"
            fi
            
            # Show last 3 log entries
            echo "Last 3 log entries:"
            echo "$LOGS" | jq -r '.events[-3:] | .[] | "  [\(.timestamp | tonumber / 1000 | strftime("%Y-%m-%d %H:%M:%S"))] \(.message)"' || echo "  No recent logs"
          done
          echo "::endgroup::"

      - name: Rollback to previous image tags on failure
        if: failure() && steps.apply.outcome == 'success' && steps.save_current_tags.outputs.previous_image_tag != ''
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          echo "::error::Deployment verification failed. Rolling back to previous image tags..."
          
          PREVIOUS_TAG="${{ steps.save_current_tags.outputs.previous_image_tag }}"
          echo "::notice::Reverting to previous image tag: ${PREVIOUS_TAG}"
          
          # Create rollback tfvars file
          cat > ${{ needs.plan.outputs.tf_path }}/ci-service-tags.auto.tfvars <<EOF
          service_image_tags = {
            api_single = "${PREVIOUS_TAG}"
            api        = "${PREVIOUS_TAG}"
            frontend   = "${PREVIOUS_TAG}"
          }
          EOF
          
          # Apply rollback
          EXTRA_ARGS=""
          if [ -f "${{ needs.plan.outputs.tf_path }}/services.generated.tfvars" ]; then
            EXTRA_ARGS="$EXTRA_ARGS -var-file=services.generated.tfvars"
          fi
          
          terraform -chdir=${{ needs.plan.outputs.tf_path }} apply \
            -auto-approve \
            $EXTRA_ARGS \
            -var="terraform_backend_bucket_name=devops-project-terraform"
          
          echo "::notice::Rollback completed. Services reverted to previous image tag: ${PREVIOUS_TAG}"
          
          # Wait for services to stabilize after rollback
          CLUSTER_NAME=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -raw ecs_cluster_name)
          SERVICE_NAMES_JSON=$(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json service_names)
          SERVICES=$(echo "$SERVICE_NAMES_JSON" | jq -r 'to_entries[] | .value')
          
          echo "::notice::Waiting for services to stabilize after rollback..."
          aws ecs wait services-stable \
            --region ${AWS_REGION} \
            --cluster $CLUSTER_NAME \
            --services $SERVICES || echo "::warning::Services may still be stabilizing after rollback"
          
          echo "::error::Deployment failed and rollback completed. Please investigate the issue."

      - name: Deployment Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY <<EOF
          ## ðŸš€ Application Deployment Summary

          **Status:** ${{ job.status == 'success' && 'âœ… Success' || 'âŒ Failed' }}
          
          **Environment:** \`${{ needs.plan.outputs.environment }}\`
          **Image Tag:** \`${{ needs.plan.outputs.image_tag }}\`
          
          **ALB Endpoints (per service):**
          \`\`\`
          $(terraform -chdir=${{ needs.plan.outputs.tf_path }} output -json alb_dns_names | jq -r 'to_entries[] | "\(.key): \(.value)"')
          \`