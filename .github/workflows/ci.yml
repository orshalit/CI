################################################################################
# CI/CD Pipeline - Production Grade
# 
# This workflow provides comprehensive CI/CD including:
# - Code quality checks (linting, formatting)
# - Security scanning
# - Unit and integration testing
# - Test coverage reporting
# - Docker image building with versioning
# - Multi-environment deployment
# - Artifact publishing
################################################################################

name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    tags:
      - 'v*'  # Always run on version tags
    paths:
      - 'applications/**'  # All application code
      - 'dhall/**'  # Dhall configuration files (service definitions affect deployments)
      - 'docker-compose*.yml'
      - 'Dockerfile*'
      - '.github/workflows/ci.yml'  # Run if CI workflow itself changes
      # Note: scripts/** removed - script changes don't require CI/CD runs
      # Scripts are validated via pre-commit hooks and can be tested manually
      # Note: paths-ignore removed - GitHub Actions doesn't allow both paths and paths-ignore
      # Markdown files in these directories won't trigger workflow (paths are specific enough)
  pull_request:
    branches: [main, develop]
    paths:
      - 'applications/**'  # All application code
      - 'dhall/**'  # Dhall configuration files (service definitions affect deployments)
      - 'docker-compose*.yml'
      - 'Dockerfile*'
      - '.github/workflows/ci.yml'
      # Note: scripts/** removed - script changes don't require CI/CD runs
      # Scripts are validated via pre-commit hooks and can be tested manually
      # Note: paths-ignore removed - GitHub Actions doesn't allow both paths and paths-ignore
      # Markdown files in these directories won't trigger workflow (paths are specific enough)
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

# Cancel in-progress runs of the same workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  # ===========================================================================
  # Change Detection (run first to determine what to execute)
  # ===========================================================================
  
  detect-changes:
    name: Detect Code Changes
    runs-on: ubuntu-latest
    outputs:
      app-code: ${{ steps.filter.outputs.app-code }}
      backend-code: ${{ steps.filter.outputs.backend-code }}
      frontend-code: ${{ steps.filter.outputs.frontend-code }}
      dhall-code: ${{ steps.filter.outputs.dhall-code }}
      app-structure-changed: ${{ steps.regenerate-compose.outputs.changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for path filtering
      
      - name: Regenerate docker-compose files (if application structure changed)
        id: regenerate-compose
        run: |
          # Check if application structure changed
          if git diff --name-only ${{ github.event.before || 'HEAD~1' }}..HEAD | grep -E '^applications/.*/(backend|frontend)/' > /dev/null; then
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "::notice::Application structure changed, regenerating per-app docker-compose files..."
            chmod +x scripts/generate-app-compose.sh
            bash scripts/generate-app-compose.sh
            
            # Check if any app compose files changed
            CHANGED_FILES=$(git diff --name-only applications/*/docker-compose.yml 2>/dev/null || echo "")
            if [ -n "$CHANGED_FILES" ]; then
              echo "::warning::docker-compose files were regenerated. Consider committing these changes."
              git diff applications/*/docker-compose.yml
            fi
          else
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "::notice::No application structure changes detected"
          fi
      
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          base: ${{ github.event.before || github.event.pull_request.base.sha || 'HEAD~1' }}
          filters: |
            app-code:
              - 'applications/**'  # All application code
              - 'dhall/**'  # Dhall service definitions (affect what gets deployed)
              - 'Dockerfile*'
              - 'docker-compose*.yml'
            backend-code:
              - 'applications/*/backend/**'
              - '**/requirements*.txt'
              - '**/pyproject.toml'
              - '**/pytest.ini'
              - '**/Dockerfile'  # Backend Dockerfiles
            frontend-code:
              - 'applications/*/frontend/**'
              - '**/package.json'
              - '**/package-lock.json'
              - '**/vite.config.*'
              - '**/Dockerfile'  # Frontend Dockerfiles
            dhall-code:
              - 'dhall/**'  # Dhall service definitions

  # ===========================================================================
  # Code Quality Checks
  # ===========================================================================
  
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    needs: [detect-changes]
    # Run if any app code changed (backend OR frontend), or on version tags, or manual dispatch
    if: |
      (needs.detect-changes.outputs.backend-code == 'true' ||
       needs.detect-changes.outputs.frontend-code == 'true' ||
       startsWith(github.ref, 'refs/tags/v') ||
       github.event_name == 'workflow_dispatch')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis
      
      - name: Detect app directories
        id: detect-apps
        run: |
          # Find all apps with backend/frontend directories
          BACKEND_APPS=$(find applications -mindepth 2 -maxdepth 2 -type d -name "backend" -exec dirname {} \; | xargs -n1 basename | jq -R -s -c 'split("\n") | map(select(length > 0))' || echo '[]')
          FRONTEND_APPS=$(find applications -mindepth 2 -maxdepth 2 -type d -name "frontend" -exec dirname {} \; | xargs -n1 basename | jq -R -s -c 'split("\n") | map(select(length > 0))' || echo '[]')
          echo "backend_apps=$BACKEND_APPS" >> $GITHUB_OUTPUT
          echo "frontend_apps=$FRONTEND_APPS" >> $GITHUB_OUTPUT
          echo "::notice::Detected backend apps: $BACKEND_APPS"
          echo "::notice::Detected frontend apps: $FRONTEND_APPS"
      
      # Python code quality - Dynamic for all app backends
      - name: Set up Python
        if: steps.detect-apps.outputs.backend_apps != '[]'
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Python dependencies for all apps
        if: steps.detect-apps.outputs.backend_apps != '[]'
        run: |
          for app_name in $(echo "${{ steps.detect-apps.outputs.backend_apps }}" | jq -r '.[]'); do
            app_backend_dir="applications/$app_name/backend"
            if [ -d "$app_backend_dir" ] && [ -f "$app_backend_dir/requirements-dev.txt" ]; then
              echo "::group::Installing dependencies for $app_name backend"
              python -m pip install --upgrade pip
              pip install -r "$app_backend_dir/requirements-dev.txt"
              echo "::endgroup::"
            fi
          done
      
      # JavaScript code quality - Dynamic for all app frontends
      - name: Set up Node.js
        if: steps.detect-apps.outputs.frontend_apps != '[]'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: Install Node.js dependencies for all apps
        if: steps.detect-apps.outputs.frontend_apps != '[]'
        run: |
          for app_name in $(echo "${{ steps.detect-apps.outputs.frontend_apps }}" | jq -r '.[]'); do
            app_frontend_dir="applications/$app_name/frontend"
            if [ -d "$app_frontend_dir" ] && [ -f "$app_frontend_dir/package-lock.json" ]; then
              echo "::group::Installing dependencies for $app_name frontend"
              cd "$app_frontend_dir"
              npm ci
              cd - > /dev/null
              echo "::endgroup::"
            fi
          done
      
      # App-specific Python code quality
      - name: Install Ruff
        if: steps.detect-apps.outputs.backend_apps != '[]'
        run: |
          python -m pip install --upgrade pip
          pip install ruff
      
      - name: Run Ruff linter for app backends
        continue-on-error: true
        run: |
          for app_dir in applications/*/backend; do
            if [ -d "$app_dir" ]; then
              app_name=$(basename $(dirname "$app_dir"))
              echo "::group::Linting $app_name backend"
              if [ -f "$app_dir/ruff.toml" ] || [ -f "$app_dir/pyproject.toml" ]; then
                ruff check "$app_dir" --output-format=github || echo "::warning::Linting failed for $app_name backend"
              else
                echo "::notice::No ruff config found for $app_name, using default"
                ruff check "$app_dir" --output-format=github || echo "::warning::Linting failed for $app_name backend"
              fi
              echo "::endgroup::"
            fi
          done
      
      - name: Check Python formatting for app backends
        continue-on-error: true
        run: |
          for app_dir in applications/*/backend; do
            if [ -d "$app_dir" ]; then
              app_name=$(basename $(dirname "$app_dir"))
              echo "::group::Formatting check for $app_name backend"
              black --check "$app_dir" || echo "::warning::Formatting issues in $app_name backend"
              echo "::endgroup::"
            fi
          done
      
      # App-specific JavaScript code quality
      - name: Run ESLint for app frontends
        continue-on-error: true
        run: |
          for app_dir in applications/*/frontend; do
            if [ -d "$app_dir" ] && [ -f "$app_dir/package.json" ]; then
              app_name=$(basename $(dirname "$app_dir"))
              echo "::group::Linting $app_name frontend"
              cd "$app_dir"
              if npm run | grep -q "lint"; then
                npm run lint || echo "::warning::Linting failed for $app_name frontend"
              else
                echo "::notice::No lint script found for $app_name frontend"
              fi
              cd - > /dev/null
              echo "::endgroup::"
            fi
          done
      
      - name: Check JavaScript formatting for app frontends
        continue-on-error: true
        run: |
          for app_dir in applications/*/frontend; do
            if [ -d "$app_dir" ] && [ -f "$app_dir/package.json" ]; then
              app_name=$(basename $(dirname "$app_dir"))
              echo "::group::Formatting check for $app_name frontend"
              cd "$app_dir"
              if npm run | grep -q "format:check"; then
                npm run format:check || echo "::warning::Formatting issues in $app_name frontend"
              else
                echo "::notice::No format:check script found for $app_name frontend"
              fi
              cd - > /dev/null
              echo "::endgroup::"
            fi
          done
      
      - name: Check for secrets in code
        if: github.event.before != github.sha
        uses: trufflesecurity/trufflehog@v3.63.7
        with:
          path: ./
          base: ${{ github.event.pull_request.base.sha || github.event.before || 'HEAD~1' }}
          head: ${{ github.event.pull_request.head.sha || github.sha }}
          extra_args: --only-verified
        continue-on-error: true

  # ===========================================================================
  # Dhall Configuration Validation
  # ===========================================================================
  
  validate-dhall:
    name: Validate Dhall Config
    runs-on: ubuntu-latest
    needs: [detect-changes]
    # Run if dhall code changed, or on version tags, or manual dispatch
    if: |
      needs.detect-changes.outputs.dhall-code == 'true' ||
      startsWith(github.ref, 'refs/tags/v') ||
      github.event_name == 'workflow_dispatch'
    
    env:
      DEVOPS_REPO_NAME: ${{ secrets.DEVOPS_REPO_NAME || 'projectdevops' }}
      DEVOPS_REPO_OWNER: ${{ secrets.DEVOPS_REPO_OWNER || 'orshalit' }}
    
    steps:
      - name: Checkout CI repository
        uses: actions/checkout@v4

      - name: Checkout DEVOPS repository
        uses: actions/checkout@v4
        with:
          repository: ${{ env.DEVOPS_REPO_OWNER }}/${{ env.DEVOPS_REPO_NAME }}
          ssh-key: ${{ secrets.DEVOPS_REPO_KEY }}
          path: DEVOPS
          ref: main

      - name: Verify DEVOPS checkout
        run: |
          if [ ! -f "DEVOPS/config/types/Service.dhall" ]; then
            echo "::error::DEVOPS/config/types/Service.dhall not found!"
            ls -la DEVOPS/ || echo "DEVOPS directory not found"
            exit 1
          fi
          echo "::notice::✓ DEVOPS/config/types/Service.dhall found"

      - name: Cache Dhall binaries
        id: cache-dhall
        uses: actions/cache@v4
        with:
          path: dhall/cache/binaries
          key: dhall-binaries-${{ runner.os }}-1.41.2
          restore-keys: |
            dhall-binaries-${{ runner.os }}-

      - name: Install Dhall
        run: |
          chmod +x scripts/install-dhall-with-fallback.sh
          scripts/install-dhall-with-fallback.sh

      - name: Type-check Dhall service definitions
        run: |
          echo "::notice::Type-checking dhall/services.dhall..."
          dhall type --file dhall/services.dhall
          echo "::notice::✓ Type-check passed"

      - name: Validate JSON generation
        run: |
          echo "::notice::Validating JSON conversion..."
          dhall-to-json --file dhall/services.dhall > /tmp/services.json
          
          if ! jq empty /tmp/services.json 2>/dev/null; then
            echo "::error::Generated JSON is invalid"
            cat /tmp/services.json
            exit 1
          fi
          
          SERVICE_COUNT=$(jq 'length' /tmp/services.json)
          echo "::notice::✓ JSON conversion successful - $SERVICE_COUNT service(s)"
          echo "::group::Generated JSON"
          jq '.' /tmp/services.json
          echo "::endgroup::"

  # ===========================================================================
  # Backend Testing
  # ===========================================================================
  
  backend-tests:
    name: Backend Tests
    runs-on: ubuntu-latest
    needs: [detect-changes]
    # Only run if backend code changed, or on version tags, or manual dispatch
    if: |
      needs.detect-changes.outputs.backend-code == 'true' ||
      startsWith(github.ref, 'refs/tags/v') ||
      github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Detect app backends
        id: detect-apps
        run: |
          APPS=$(find applications -mindepth 2 -maxdepth 2 -type d -name "backend" -exec dirname {} \; | xargs -n1 basename | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "apps=$APPS" >> $GITHUB_OUTPUT
          echo "::notice::Detected app backends: $APPS"
      
      - name: Set up Python
        if: steps.detect-apps.outputs.apps != '[]'
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Run tests for each app backend
        if: steps.detect-apps.outputs.apps != '[]'
        continue-on-error: true
        run: |
          for app_name in $(echo "${{ steps.detect-apps.outputs.apps }}" | jq -r '.[]'); do
            app_backend_dir="applications/$app_name/backend"
            
            if [ ! -d "$app_backend_dir" ]; then
              echo "::warning::Backend directory not found: $app_backend_dir"
              continue
            fi
            
            if [ ! -d "$app_backend_dir/tests" ] && [ ! -f "$app_backend_dir/pytest.ini" ]; then
              echo "::notice::No tests found for $app_name backend, skipping"
              continue
            fi
            
            echo "::group::Testing $app_name backend"
            
            # Install dependencies
            if [ -f "$app_backend_dir/requirements-dev.txt" ]; then
              python -m pip install --upgrade pip
              pip install -r "$app_backend_dir/requirements-dev.txt"
            elif [ -f "$app_backend_dir/requirements.txt" ]; then
              python -m pip install --upgrade pip
              pip install -r "$app_backend_dir/requirements.txt"
            fi
            
            # Run unit tests
            cd "$app_backend_dir"
            if [ -d "tests" ]; then
              echo "Running unit tests for $app_name..."
              pytest -m unit \
                --verbose \
                --tb=short \
                --cov=. \
                --cov-report=xml \
                --cov-report=html \
                --cov-report=term-missing \
                --junitxml=junit-$app_name-unit.xml \
                tests/ || echo "::warning::Unit tests failed for $app_name"
              
              # Run integration tests if they exist
              if pytest -m integration --collect-only tests/ 2>/dev/null | grep -q "integration"; then
                echo "Running integration tests for $app_name..."
                # Start services for integration tests
                cd ../../..
                docker compose -f docker-compose.base.yml up -d database || true
                
                # Build and start the app-specific backend service (dynamic)
                BACKEND_SERVICE="${app_name}-backend"
                APP_COMPOSE="applications/${app_name}/docker-compose.yml"
                docker compose -f docker-compose.base.yml -f "$APP_COMPOSE" build "$BACKEND_SERVICE" || {
                  echo "::warning::Failed to build $BACKEND_SERVICE"
                  exit 1
                }
                docker compose -f docker-compose.base.yml -f "$APP_COMPOSE" up -d "$BACKEND_SERVICE" || {
                  echo "::warning::Failed to start $BACKEND_SERVICE"
                  exit 1
                }
                
                # Get backend port from docker-compose (dynamic - handles port conflicts)
                BACKEND_PORT=$(docker compose config --services | grep -E "^${app_name}-backend$" > /dev/null && \
                  docker compose config | grep -A 20 "^  ${app_name}-backend:" | grep -E "^\s+-.*:8000" | head -1 | sed 's/.*:\([0-9]*\):8000/\1/' || echo "8000")
                
                # Wait for services
                timeout 60 bash -c "until curl -f http://localhost:${BACKEND_PORT}/health 2>/dev/null; do sleep 2; done" || true
                
                # Run integration tests
                cd "applications/$app_name/backend"
                pytest -m integration \
                  --verbose \
                  --tb=short \
                  --junitxml=junit-$app_name-integration.xml \
                  tests/ || echo "::warning::Integration tests failed for $app_name"
                
                # Stop services
                cd ../../..
                docker compose -f docker-compose.base.yml -f "applications/${app_name}/docker-compose.yml" down -v || true
              fi
            fi
            cd - > /dev/null
            
            echo "::endgroup::"
          done
      
      - name: Upload test results
        if: always() && steps.detect-apps.outputs.apps != '[]'
        uses: actions/upload-artifact@v4
        with:
          name: backend-test-results
          path: applications/*/backend/junit-*.xml
          if-no-files-found: ignore
      
      - name: Upload coverage to Codecov
        if: always() && steps.detect-apps.outputs.apps != '[]'
        uses: codecov/codecov-action@v4
        with:
          files: applications/*/backend/coverage.xml
          flags: backend
          name: backend-coverage
          fail_ci_if_error: false

  # ===========================================================================
  # App-Specific Backend Testing
  # ===========================================================================
  
  app-backend-tests:
    name: App-Specific Backend Tests
    runs-on: ubuntu-latest
    needs: [detect-changes]
    # Only run if backend code changed, or on version tags, or manual dispatch
    if: |
      needs.detect-changes.outputs.backend-code == 'true' ||
      startsWith(github.ref, 'refs/tags/v') ||
      github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Detect app backends with tests
        id: detect-apps
        run: |
          APPS=$(find applications -mindepth 2 -maxdepth 2 -type d -name "backend" -exec dirname {} \; | xargs -n1 basename | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "apps=$APPS" >> $GITHUB_OUTPUT
          echo "::notice::Detected app backends: $APPS"
      
      - name: Run tests for each app backend
        if: steps.detect-apps.outputs.apps != '[]'
        continue-on-error: true
        run: |
          for app_name in $(echo "${{ steps.detect-apps.outputs.apps }}" | jq -r '.[]'); do
            app_backend_dir="applications/$app_name/backend"
            
            if [ ! -d "$app_backend_dir" ]; then
              echo "::warning::Backend directory not found: $app_backend_dir"
              continue
            fi
            
            if [ ! -d "$app_backend_dir/tests" ] && [ ! -f "$app_backend_dir/pytest.ini" ]; then
              echo "::notice::No tests found for $app_name backend, skipping"
              continue
            fi
            
            echo "::group::Testing $app_name backend"
            
            # Install dependencies if requirements exist
            if [ -f "$app_backend_dir/requirements.txt" ]; then
              echo "Installing dependencies for $app_name..."
              pip install -r "$app_backend_dir/requirements.txt"
            fi
            
            if [ -f "$app_backend_dir/requirements-dev.txt" ]; then
              echo "Installing dev dependencies for $app_name..."
              pip install -r "$app_backend_dir/requirements-dev.txt"
            fi
            
            # Run tests
            cd "$app_backend_dir"
            if [ -f "pytest.ini" ] || [ -d "tests" ]; then
              echo "Running tests for $app_name backend..."
              pytest \
                --verbose \
                --tb=short \
                --junitxml=junit-$app_name.xml \
                tests/ || echo "::warning::Tests failed for $app_name backend"
            fi
            cd - > /dev/null
            
            echo "::endgroup::"
          done
      
      - name: Upload app backend test results
        if: always() && steps.detect-apps.outputs.apps != '[]'
        uses: actions/upload-artifact@v4
        with:
          name: app-backend-test-results
          path: applications/*/backend/junit-*.xml
          if-no-files-found: ignore

  # ===========================================================================
  # Frontend Testing
  # ===========================================================================
  
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest
    needs: [detect-changes]
    # Only run if frontend code changed, or on version tags, or manual dispatch
    if: |
      needs.detect-changes.outputs.frontend-code == 'true' ||
      startsWith(github.ref, 'refs/tags/v') ||
      github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: Detect app frontends with tests
        id: detect-apps
        run: |
          APPS=$(find applications -mindepth 2 -maxdepth 2 -type d -name "frontend" -exec dirname {} \; | xargs -n1 basename | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "apps=$APPS" >> $GITHUB_OUTPUT
          echo "::notice::Detected app frontends: $APPS"
      
      - name: Run tests for each app frontend
        if: steps.detect-apps.outputs.apps != '[]'
        continue-on-error: true
        run: |
          for app_name in $(echo "${{ steps.detect-apps.outputs.apps }}" | jq -r '.[]'); do
            app_frontend_dir="applications/$app_name/frontend"
            
            if [ ! -d "$app_frontend_dir" ]; then
              echo "::warning::Frontend directory not found: $app_frontend_dir"
              continue
            fi
            
            if [ ! -f "$app_frontend_dir/package.json" ]; then
              echo "::notice::No package.json found for $app_name frontend, skipping"
              continue
            fi
            
            echo "::group::Testing $app_name frontend"
            
            # Install dependencies
            cd "$app_frontend_dir"
            echo "Installing dependencies for $app_name frontend..."
            npm ci || echo "::warning::npm ci failed for $app_name, trying npm install"
            npm install || echo "::warning::npm install failed for $app_name"
            
            # Run tests if test script exists
            if npm run | grep -q "test"; then
              echo "Running tests for $app_name frontend..."
              npm test -- --coverage --watchAll=false --ci --maxWorkers=50% || echo "::warning::Tests failed for $app_name frontend"
            else
              echo "::notice::No test script found in $app_name frontend package.json"
            fi
            
            cd - > /dev/null
            
            echo "::endgroup::"
          done
      
      - name: Upload app frontend test results
        if: always() && steps.detect-apps.outputs.apps != '[]'
        uses: actions/upload-artifact@v4
        with:
          name: app-frontend-test-results
          path: applications/*/frontend/coverage/
          if-no-files-found: ignore

  # ===========================================================================
  # Build Metadata Preparation
  # ===========================================================================
  
  prepare-build:
    name: Prepare Build Metadata
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.metadata.outputs.version }}
      commit: ${{ steps.metadata.outputs.commit }}
      branch: ${{ steps.metadata.outputs.branch }}
      build_date: ${{ steps.metadata.outputs.build_date }}
      is_release: ${{ steps.metadata.outputs.is_release }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git describe
      
      - name: Generate build metadata
        id: metadata
        run: |
          # Determine version
          if [[ "${{ github.ref }}" == refs/tags/v* ]]; then
            VERSION="${{ github.ref_name }}"
            IS_RELEASE="true"
          elif [[ "${{ github.ref }}" == refs/heads/main ]]; then
            VERSION="main-$(git rev-parse --short HEAD)"
            IS_RELEASE="false"
          else
            VERSION="dev-$(git rev-parse --short HEAD)"
            IS_RELEASE="false"
          fi
          
          # Get git metadata
          COMMIT=$(git rev-parse --short HEAD)
          BRANCH=${GITHUB_REF#refs/heads/}
          BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          
          # Output for use in other jobs
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "commit=${COMMIT}" >> $GITHUB_OUTPUT
          echo "branch=${BRANCH}" >> $GITHUB_OUTPUT
          echo "build_date=${BUILD_DATE}" >> $GITHUB_OUTPUT
          echo "is_release=${IS_RELEASE}" >> $GITHUB_OUTPUT
          
          # Display metadata
          echo "::notice::Build Version: ${VERSION}"
          echo "::notice::Git Commit: ${COMMIT}"
          echo "::notice::Git Branch: ${BRANCH}"
          echo "::notice::Build Date: ${BUILD_DATE}"

      - name: Persist build version for downstream workflows
        run: |
          echo "${{ steps.metadata.outputs.version }}" > build-version.txt
        shell: bash

      - name: Upload build version artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-version
          path: build-version.txt
          retention-days: 7  # Keep artifact for 7 days for deployment workflows
          if-no-files-found: error  # Fail if file doesn't exist

      # Note: built-images.txt is now created and uploaded by each matrix build job
      # GitHub Actions will automatically merge artifacts with the same name when downloading
      # This ensures the deployment workflow gets all successfully built images

  # ===========================================================================
  # Docker Image Building
  # ===========================================================================
  
  detect-app-images:
    name: Detect Application Images to Build
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Detect images to build
        id: set-matrix
        run: |
          chmod +x scripts/detect-app-images.sh
          scripts/detect-app-images.sh --format matrix > matrix.json
          echo "matrix<<EOF" >> $GITHUB_OUTPUT
          cat matrix.json >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "::notice::Build matrix:"
          cat matrix.json | jq -r '.include[] | "  - \(.image_name) (\(.type))"'
    
  filter-build-matrix:
    name: Filter Build Matrix
    runs-on: ubuntu-latest
    needs: [detect-changes, detect-app-images]
    outputs:
      matrix: ${{ steps.filter.outputs.matrix }}
      has_images: ${{ steps.filter.outputs.has_images }}
    steps:
      - name: Filter matrix by changed code
        id: filter
        run: |
          BACKEND_CHANGED="${{ needs.detect-changes.outputs.backend-code }}"
          FRONTEND_CHANGED="${{ needs.detect-changes.outputs.frontend-code }}"
          APP_CODE_CHANGED="${{ needs.detect-changes.outputs.app-code }}"
          FULL_MATRIX='${{ needs.detect-app-images.outputs.matrix }}'
          
          echo "::group::Change Detection Debug"
          echo "Backend changed: $BACKEND_CHANGED"
          echo "Frontend changed: $FRONTEND_CHANGED"
          echo "App code changed: $APP_CODE_CHANGED"
          echo "Full matrix:"
          echo "$FULL_MATRIX" | jq '.'
          echo "::endgroup::"
          
          # If both changed or tag/manual, use full matrix
          if [ "${{ startsWith(github.ref, 'refs/tags/v') }}" == "true" ] || [ "${{ github.event_name == 'workflow_dispatch' }}" == "true" ]; then
            echo "matrix<<EOF" >> $GITHUB_OUTPUT
            echo "$FULL_MATRIX" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            COUNT=$(echo "$FULL_MATRIX" | jq '.include | length')
            echo "has_images=$([ "$COUNT" -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
            echo "::notice::Building all images (tag/manual trigger)"
            exit 0
          fi
          
          # Filter matrix based on what changed
          # Build only what changed to avoid unnecessary builds and costs
          if [ "$BACKEND_CHANGED" == "true" ] && [ "$FRONTEND_CHANGED" == "true" ]; then
            echo "matrix<<EOF" >> $GITHUB_OUTPUT
            echo "$FULL_MATRIX" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            COUNT=$(echo "$FULL_MATRIX" | jq '.include | length')
            echo "has_images=$([ "$COUNT" -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
            echo "::notice::Building all images (both backend and frontend changed)"
          elif [ "$BACKEND_CHANGED" == "true" ]; then
            # Build all backend images (app-specific backends in applications/*/backend)
            FILTERED=$(echo "$FULL_MATRIX" | jq '.include | map(select(.service == "backend")) | {include: .}')
            COUNT=$(echo "$FILTERED" | jq '.include | length')
            if [ "$COUNT" -eq 0 ]; then
              echo "::warning::Backend code changed but no backend images found in matrix, using full matrix"
              echo "matrix<<EOF" >> $GITHUB_OUTPUT
              echo "$FULL_MATRIX" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
              FALLBACK_COUNT=$(echo "$FULL_MATRIX" | jq '.include | length')
              echo "has_images=$([ "$FALLBACK_COUNT" -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
            else
              echo "matrix<<EOF" >> $GITHUB_OUTPUT
              echo "$FILTERED" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
              echo "has_images=true" >> $GITHUB_OUTPUT
              echo "::notice::Building backend images ($COUNT image(s))"
            fi
          elif [ "$FRONTEND_CHANGED" == "true" ]; then
            # Build all frontend images (app-specific frontends in applications/*/frontend)
            FILTERED=$(echo "$FULL_MATRIX" | jq '.include | map(select(.service == "frontend")) | {include: .}')
            COUNT=$(echo "$FILTERED" | jq '.include | length')
            if [ "$COUNT" -eq 0 ]; then
              echo "::warning::Frontend code changed but no frontend images found in matrix, using full matrix"
              echo "matrix<<EOF" >> $GITHUB_OUTPUT
              echo "$FULL_MATRIX" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
              FALLBACK_COUNT=$(echo "$FULL_MATRIX" | jq '.include | length')
              echo "has_images=$([ "$FALLBACK_COUNT" -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
            else
              echo "matrix<<EOF" >> $GITHUB_OUTPUT
              echo "$FILTERED" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
              echo "has_images=true" >> $GITHUB_OUTPUT
              echo "::notice::Building frontend images ($COUNT image(s))"
            fi
          elif [ "$APP_CODE_CHANGED" == "true" ]; then
            # App code changed but not specifically backend or frontend (e.g., Dockerfile, dhall, docker-compose)
            # Build all app-specific images as a fallback
            FILTERED=$(echo "$FULL_MATRIX" | jq '.include | map(select(.type == "app-specific")) | {include: .}')
            COUNT=$(echo "$FILTERED" | jq '.include | length')
            if [ "$COUNT" -eq 0 ]; then
              echo "::warning::App code changed but no app-specific images found, using full matrix"
              echo "matrix<<EOF" >> $GITHUB_OUTPUT
              echo "$FULL_MATRIX" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
              FALLBACK_COUNT=$(echo "$FULL_MATRIX" | jq '.include | length')
              echo "has_images=$([ "$FALLBACK_COUNT" -gt 0 ] && echo "true" || echo "false")" >> $GITHUB_OUTPUT
            else
              echo "matrix<<EOF" >> $GITHUB_OUTPUT
              echo "$FILTERED" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
              echo "has_images=true" >> $GITHUB_OUTPUT
              echo "::notice::Building all app-specific images ($COUNT image(s)) - app infrastructure changed"
            fi
          else
            echo "matrix={\"include\": []}" >> $GITHUB_OUTPUT
            echo "has_images=false" >> $GITHUB_OUTPUT
            echo "::warning::No code changes detected, skipping builds"
            echo "::warning::This might be a path filter issue - check the detect-changes job output"
          fi

  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [code-quality, backend-tests, frontend-tests, app-backend-tests, prepare-build, detect-changes, filter-build-matrix, validate-dhall]
    # We must use `always()` so this job's `if` condition is evaluated even if upstream jobs are skipped.
    # The condition then checks that all necessary preceding jobs either succeeded or were skipped,
    # and most importantly, that the filter-build-matrix job has determined there are images to build.
    if: |
      always() &&
      needs.filter-build-matrix.outputs.has_images == 'true' &&
      (needs.prepare-build.result == 'success') &&
      (needs.detect-changes.result == 'success') &&
      (needs.filter-build-matrix.result == 'success') &&
      (needs.code-quality.result == 'success' || needs.code-quality.result == 'skipped') &&
      (needs.backend-tests.result == 'success' || needs.backend-tests.result == 'skipped') &&
      (needs.frontend-tests.result == 'success' || needs.frontend-tests.result == 'skipped') &&
      (needs.validate-dhall.result == 'success' || needs.validate-dhall.result == 'skipped') &&
      (needs.app-backend-tests.result == 'success' || needs.app-backend-tests.result == 'skipped') &&
      (needs.frontend-tests.result == 'success' || needs.frontend-tests.result == 'skipped')
    strategy:
      matrix: ${{ fromJson(needs.filter-build-matrix.outputs.matrix) }}
      fail-fast: false
    
    steps:
      - name: Validate Build Matrix
        run: |
          MATRIX_JSON='${{ needs.filter-build-matrix.outputs.matrix }}'
          echo "::debug::Raw matrix JSON: $MATRIX_JSON"
          
          # Check if the matrix is empty or invalid
          if [ "$MATRIX_JSON" == "null" ] || [ "$MATRIX_JSON" == "{\\"include\\":[]}" ]; then
            echo "::error::Build matrix is empty or invalid. No images will be built."
            echo "::error::This usually means no relevant code changes were detected by 'detect-changes' or 'filter-build-matrix'."
            echo "::error::If this is unexpected, review the 'detect-changes' and 'filter-build-matrix' job outputs."
            exit 1
          fi
          
          # Further validation: check if 'include' array exists and has elements
          if ! echo "$MATRIX_JSON" | jq -e '.include | length > 0' > /dev/null; then
            echo "::error::Build matrix 'include' array is empty. No images will be built."
            echo "::error::Review the 'filter-build-matrix' job output for details."
            exit 1
          fi
          
          echo "::notice::Build matrix validated. Images to build:"
          echo "$MATRIX_JSON" | jq -r '.include[] | "  - \\(.image_name) (type: \\(.type), context: \\(.context))"'
      
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to GitHub Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository_owner }}/${{ matrix.image_name }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=semver,pattern={{major}}
            type=sha,prefix={{branch}}-
            type=raw,value=${{ needs.prepare-build.outputs.version }}
            type=raw,value=latest,enable={{is_default_branch}}
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.context }}
          file: ${{ matrix.dockerfile }}
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            BUILD_VERSION=${{ needs.prepare-build.outputs.version }}
            GIT_COMMIT=${{ needs.prepare-build.outputs.commit }}
            GIT_BRANCH=${{ needs.prepare-build.outputs.branch }}
            BUILD_DATE=${{ needs.prepare-build.outputs.build_date }}
          cache-from: type=gha,scope=${{ matrix.image_name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.image_name }}
          platforms: linux/amd64
      
      - name: Record successfully built image
        if: success()
        run: |
          # Create built-images.txt with header if it doesn't exist
          if [ ! -f "built-images.txt" ]; then
            echo "# Images successfully built in this CI run" > built-images.txt
            echo "# Format: image_name (one per line)" >> built-images.txt
            echo "# Used by deployment workflow to filter services" >> built-images.txt
          fi
          # Append image name to built-images list (for deployment filtering)
          echo "${{ matrix.image_name }}" >> built-images.txt
          echo "::notice::✓ Built image: ${{ matrix.image_name }}"
      
      - name: Upload built images list artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: built-images-${{ matrix.image_name }}
          path: built-images.txt
          retention-days: 7
          if-no-files-found: ignore
          # Using per-image artifact name to avoid conflicts in matrix
      
      - name: Export image for testing
        if: github.event_name == 'pull_request'
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.context }}
          file: ${{ matrix.dockerfile }}
          tags: ${{ matrix.image_name }}:test
          build-args: |
            BUILD_VERSION=${{ needs.prepare-build.outputs.version }}
            GIT_COMMIT=${{ needs.prepare-build.outputs.commit }}
            GIT_BRANCH=${{ needs.prepare-build.outputs.branch }}
            BUILD_DATE=${{ needs.prepare-build.outputs.build_date }}
          cache-from: type=gha,scope=${{ matrix.image_name }}
          load: true

  # ===========================================================================
  # Collect built images from matrix jobs
  # ===========================================================================

  collect-built-images:
    name: Collect built images from matrix jobs
    runs-on: ubuntu-latest
    needs: [build-images]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download built images artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: built-images-*
          # Do NOT use merge-multiple: true - files with same name overwrite each other!
          # Without merge-multiple, each artifact gets its own subdirectory
          path: collected-built-images
        continue-on-error: true

      - name: Merge built-images.txt files
        run: |
          OUTPUT="built-images.txt"
          echo "# Images successfully built in this CI run" > "$OUTPUT"
          echo "# Format: image_name (one per line)" >> "$OUTPUT"
          echo "# Used by deployment workflow to filter services" >> "$OUTPUT"
          
          # Debug: Show downloaded structure
          echo "::group::Downloaded artifacts structure"
          ls -la collected-built-images/ 2>/dev/null || echo "No artifacts downloaded"
          find collected-built-images -type f -name "*.txt" 2>/dev/null || echo "No .txt files found"
          echo "::endgroup::"
          
          # Find and merge all built-images.txt files from subdirectories
          # Structure is: collected-built-images/<artifact-name>/built-images.txt
          if find collected-built-images -name "built-images.txt" -type f 2>/dev/null | grep -q .; then
            find collected-built-images -name "built-images.txt" -type f -exec cat {} \; >> "$OUTPUT"
            echo "::notice::Found and merged built-images.txt files"
          else
            echo "::warning::No built-images.txt files found in artifacts"
          fi
          
          # Remove blank/comment lines and deduplicate
          grep -v '^#' "$OUTPUT" | grep -v '^$' | sort -u > "${OUTPUT}.tmp" || true
          mv "${OUTPUT}.tmp" "$OUTPUT"
          
          # Debug: Show final content
          echo "::group::Final built-images.txt content"
          cat "$OUTPUT" || echo "File is empty"
          echo "::endgroup::"

      - name: Upload merged built images artifact
        uses: actions/upload-artifact@v4
        with:
          name: built-images
          path: built-images.txt
          retention-days: 7
          if-no-files-found: warn

  # ===========================================================================
  # End-to-End Tests
  # ===========================================================================
  
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [build-images, prepare-build, detect-changes, filter-build-matrix]
    # We must use `always()` so this job's `if` condition is evaluated even if upstream jobs are skipped.
    if: |
      always() &&
      (needs.detect-changes.outputs.backend-code == 'true' ||
       needs.detect-changes.outputs.frontend-code == 'true' ||
       startsWith(github.ref, 'refs/tags/v') ||
       github.event_name == 'workflow_dispatch') &&
      (needs.build-images.result == 'success' || needs.build-images.result == 'skipped') &&
      (needs.prepare-build.result == 'success') &&
      (needs.filter-build-matrix.result == 'success')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Regenerate docker-compose files (ensure up-to-date)
        run: |
          chmod +x scripts/generate-app-compose.sh
          bash scripts/generate-app-compose.sh
          echo "::notice::Per-app docker-compose files regenerated with latest application structure"
      
      - name: Start services with docker compose
        env:
          BUILD_VERSION: ${{ needs.prepare-build.outputs.version }}
          GIT_COMMIT: ${{ needs.prepare-build.outputs.commit }}
          GIT_BRANCH: ${{ needs.prepare-build.outputs.branch }}
          BUILD_DATE: ${{ needs.prepare-build.outputs.build_date }}
        run: |
          # Build compose file list (base + all app compose files)
          COMPOSE_FILES="-f docker-compose.base.yml"
          for APP_COMPOSE in applications/*/docker-compose.yml; do
            if [ -f "$APP_COMPOSE" ]; then
              COMPOSE_FILES="$COMPOSE_FILES -f $APP_COMPOSE"
            fi
          done
          docker compose $COMPOSE_FILES up -d --build
      
      - name: Detect application services from docker-compose
        id: detect-services
        run: |
          # Build compose file list (base + all app compose files)
          COMPOSE_FILES="-f docker-compose.base.yml"
          for APP_COMPOSE in applications/*/docker-compose.yml; do
            if [ -f "$APP_COMPOSE" ]; then
              COMPOSE_FILES="$COMPOSE_FILES -f $APP_COMPOSE"
            fi
          done
          
          # Get all services from docker-compose (dynamic)
          echo "::group::Service Detection Debug"
          echo "Compose files: $COMPOSE_FILES"
          echo "Raw services output:"
          docker compose $COMPOSE_FILES config --services || echo "Failed to get services"
          echo "::endgroup::"
          
          # Get all services (excluding database)
          ALL_SERVICES_RAW=$(docker compose $COMPOSE_FILES config --services 2>/dev/null | grep -v "^database$" || echo "")
          
          if [ -z "$ALL_SERVICES_RAW" ]; then
            echo "::warning::No services found in docker-compose files"
            echo "backend_services=" >> $GITHUB_OUTPUT
            echo "frontend_services=" >> $GITHUB_OUTPUT
            echo "all_services=" >> $GITHUB_OUTPUT
            echo "compose_files=$COMPOSE_FILES" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Convert newlines to spaces for GitHub Actions output (doesn't support multi-line)
          ALL_SERVICES=$(echo "$ALL_SERVICES_RAW" | tr '\n' ' ' | sed 's/ $//')
          
          # Debug: Show raw services before filtering
          echo "::group::Debug: Raw service detection"
          echo "ALL_SERVICES_RAW (newline-separated):"
          echo "$ALL_SERVICES_RAW" | while read -r service; do
            echo "  - '$service'"
          done
          echo "ALL_SERVICES (space-separated): '$ALL_SERVICES'"
          echo "::endgroup::"
          
          # Filter backend/frontend services (ensure we filter before converting to spaces)
          # Use -- to prevent grep from interpreting patterns starting with - as options
          BACKEND_SERVICES_RAW=$(echo "$ALL_SERVICES_RAW" | grep -E -- "-backend$" || true)
          FRONTEND_SERVICES_RAW=$(echo "$ALL_SERVICES_RAW" | grep -E -- "-frontend$" || true)
          
          # Ensure empty strings if no matches found
          if [ -z "$BACKEND_SERVICES_RAW" ]; then
            BACKEND_SERVICES_RAW=""
          fi
          if [ -z "$FRONTEND_SERVICES_RAW" ]; then
            FRONTEND_SERVICES_RAW=""
          fi
          
          BACKEND_SERVICES=$(echo "$BACKEND_SERVICES_RAW" | tr '\n' ' ' | sed 's/ $//' || echo "")
          FRONTEND_SERVICES=$(echo "$FRONTEND_SERVICES_RAW" | tr '\n' ' ' | sed 's/ $//' || echo "")
          
          # Debug output
          echo "::group::Debug: Service filtering results"
          echo "BACKEND_SERVICES_RAW (newline-separated):"
          if [ -n "$BACKEND_SERVICES_RAW" ]; then
            echo "$BACKEND_SERVICES_RAW" | while read -r service; do
              echo "  - '$service'"
            done
          else
            echo "  (empty)"
          fi
          echo "BACKEND_SERVICES (space-separated): '$BACKEND_SERVICES'"
          echo "FRONTEND_SERVICES (space-separated): '$FRONTEND_SERVICES'"
          echo "::endgroup::"
          
          echo "::notice::Service detection results:"
          echo "  All services: '$ALL_SERVICES'"
          echo "  Backend services: '$BACKEND_SERVICES'"
          echo "  Frontend services: '$FRONTEND_SERVICES'"
          
          echo "backend_services=$BACKEND_SERVICES" >> $GITHUB_OUTPUT
          echo "frontend_services=$FRONTEND_SERVICES" >> $GITHUB_OUTPUT
          echo "all_services=$ALL_SERVICES" >> $GITHUB_OUTPUT
          echo "compose_files=$COMPOSE_FILES" >> $GITHUB_OUTPUT
          
          echo "::notice::Detected services:"
          echo "  All: $ALL_SERVICES"
          echo "  Backend: $BACKEND_SERVICES"
          echo "  Frontend: $FRONTEND_SERVICES"

      - name: Wait for services to be healthy
        run: |
          # Build compose file list
          COMPOSE_FILES="${{ steps.detect-services.outputs.compose_files }}"
          
          echo "Waiting for services to be healthy..."
          
          echo "=== Waiting for database ==="
          timeout 120 bash -c "
            until docker compose $COMPOSE_FILES ps database | grep -q \"healthy\"; do 
              echo \"Waiting for database...\"; 
              sleep 2; 
            done
          "
          echo "✓ Database is healthy"
          
          # Build compose file list
          COMPOSE_FILES="${{ steps.detect-services.outputs.compose_files }}"
          
          # Wait for all backend services (dynamic)
          # Services are space-separated (converted from newlines for GitHub Actions)
          BACKEND_SERVICES="${{ steps.detect-services.outputs.backend_services }}"
          if [ -n "$BACKEND_SERVICES" ]; then
            # Convert space-separated to array for iteration
            for BACKEND_SERVICE in $BACKEND_SERVICES; do
              echo "=== Waiting for $BACKEND_SERVICE ==="
              timeout 120 bash -c "
                until docker compose $COMPOSE_FILES ps $BACKEND_SERVICE | grep -q \"healthy\"; do 
                  echo \"Waiting for $BACKEND_SERVICE...\"; 
                  sleep 2; 
                done
              "
              echo "✓ $BACKEND_SERVICE is healthy"
            done
          else
            echo "::warning::No backend services detected"
          fi
          
          # Wait for all frontend services (dynamic)
          # Services are space-separated (converted from newlines for GitHub Actions)
          FRONTEND_SERVICES="${{ steps.detect-services.outputs.frontend_services }}"
          if [ -n "$FRONTEND_SERVICES" ]; then
            # Convert space-separated to array for iteration
            for FRONTEND_SERVICE in $FRONTEND_SERVICES; do
              echo "=== Waiting for $FRONTEND_SERVICE ==="
              echo "Container status before wait:"
              docker compose $COMPOSE_FILES ps "$FRONTEND_SERVICE"
              
              timeout 120 bash -c "
                counter=0
                until docker compose $COMPOSE_FILES ps \"$FRONTEND_SERVICE\" | grep -q \"healthy\"; do 
                  counter=\$((counter + 1))
                  echo \"Waiting for $FRONTEND_SERVICE... (attempt \$counter)\"
                  
                  # Every 10 attempts, show detailed debug info
                  if [ \$((counter % 10)) -eq 0 ]; then
                    echo \"--- Debug Info (attempt \$counter) ---\"
                    echo \"Container status:\"
                    docker compose $COMPOSE_FILES ps \"$FRONTEND_SERVICE\"
                    echo \"Health check status:\"
                    docker inspect --format='{{json .State.Health}}' \"$FRONTEND_SERVICE\" 2>/dev/null | jq . || echo \"No health info available\"
                    echo \"Recent logs:\"
                    docker compose $COMPOSE_FILES logs --tail=20 \"$FRONTEND_SERVICE\"
                    echo \"---\"
                  fi
                  
                  sleep 2
                done
              "
              echo "✓ $FRONTEND_SERVICE is healthy"
            done
          else
            echo "::warning::No frontend services detected"
          fi
      
      - name: Verify service health
        run: |
          # Build compose file list
          COMPOSE_FILES="${{ steps.detect-services.outputs.compose_files }}"
          
          echo "=== Service Status ==="
          docker compose $COMPOSE_FILES ps
          
          echo -e "\n=== Database Health ==="
          docker compose $COMPOSE_FILES exec -T database pg_isready -U appuser -d appdb
          
          # Verify all backend services (dynamic)
          BACKEND_SERVICES="${{ steps.detect-services.outputs.backend_services }}"
          if [ -n "$BACKEND_SERVICES" ]; then
            for BACKEND_SERVICE in $BACKEND_SERVICES; do
              # Get port from docker-compose config
              BACKEND_PORT=$(docker compose $COMPOSE_FILES config | grep -A 30 "^  ${BACKEND_SERVICE}:" | grep -E "^\s+-.*:8000" | head -1 | sed -E 's/.*:([0-9]+):8000/\1/' || echo "8000")
              
              echo -e "\n=== ${BACKEND_SERVICE} Health (port ${BACKEND_PORT}) ==="
              curl -f "http://localhost:${BACKEND_PORT}/health" | jq . || echo "Health check failed"
              
              echo -e "\n=== ${BACKEND_SERVICE} Version ==="
              curl -f "http://localhost:${BACKEND_PORT}/version" | jq . || echo "Version check failed"
            done
          fi
          
          # Verify all frontend services (dynamic)
          FRONTEND_SERVICES="${{ steps.detect-services.outputs.frontend_services }}"
          if [ -n "$FRONTEND_SERVICES" ]; then
            for FRONTEND_SERVICE in $FRONTEND_SERVICES; do
              # Get port from docker-compose config
              FRONTEND_PORT=$(docker compose $COMPOSE_FILES config | grep -A 30 "^  ${FRONTEND_SERVICE}:" | grep -E "^\s+-.*:3000" | head -1 | sed -E 's/.*:([0-9]+):3000/\1/' || echo "3000")
              
              echo -e "\n=== ${FRONTEND_SERVICE} Health (port ${FRONTEND_PORT}) ==="
              curl -f "http://localhost:${FRONTEND_PORT}/" > /dev/null || echo "Health check failed"
              
              echo -e "\n=== ${FRONTEND_SERVICE} Version ==="
              curl -f "http://localhost:${FRONTEND_PORT}/version.json" | jq . || echo "Version check failed"
            done
          fi
      
      - name: Run E2E API tests
        run: |
          # Build compose file list (same as detect-services step)
          COMPOSE_FILES="${{ steps.detect-services.outputs.compose_files }}"
          
          # Get first backend service and its port (dynamic)
          BACKEND_SERVICES="${{ steps.detect-services.outputs.backend_services }}"
          if [ -z "$BACKEND_SERVICES" ]; then
            echo "::error::No backend services found for E2E tests"
            echo "::error::Detected services output: '$BACKEND_SERVICES'"
            echo "::error::All services: '${{ steps.detect-services.outputs.all_services }}'"
            exit 1
          fi
          
          # Get first backend service (space-separated format)
          FIRST_BACKEND=$(echo "$BACKEND_SERVICES" | awk '{print $1}')
          
          # Debug: Show docker compose config for port extraction
          echo "::group::Debug: Port extraction for $FIRST_BACKEND"
          echo "Docker compose config for service:"
          docker compose $COMPOSE_FILES config | grep -A 30 "^  ${FIRST_BACKEND}:" || echo "Service not found in config"
          echo "::endgroup::"
          
          # Extract port - handle both variable expansion and direct port formats
          # Format can be: "8000:8000" or "${VAR:-8000}:8000" (after docker compose config expansion)
          BACKEND_PORT=$(docker compose $COMPOSE_FILES config 2>/dev/null | \
            grep -A 30 "^  ${FIRST_BACKEND}:" | \
            grep -E "^\s+-\s+.*:8000" | \
            head -1 | \
            sed -E 's/.*:([0-9]+):8000/\1/' || echo "8000")
          
          # Fallback: if port extraction failed, try alternative pattern
          if [ -z "$BACKEND_PORT" ] || [ "$BACKEND_PORT" = "8000" ]; then
            # Try to get port from actual running container
            BACKEND_PORT=$(docker compose $COMPOSE_FILES ps --format json 2>/dev/null | \
              jq -r ".[] | select(.Service == \"$FIRST_BACKEND\") | .Publishers[0].PublishedPort // empty" 2>/dev/null || echo "")
            if [ -z "$BACKEND_PORT" ]; then
              BACKEND_PORT="8000"  # Default fallback
              echo "::warning::Could not extract port, using default: $BACKEND_PORT"
            else
              echo "::notice::Extracted port from running container: $BACKEND_PORT"
            fi
          fi
          
          BACKEND_URL="http://localhost:${BACKEND_PORT}"
          
          echo "::notice::Using backend: $FIRST_BACKEND on port $BACKEND_PORT"
          echo "=== Testing Hello Endpoint (${FIRST_BACKEND} on port ${BACKEND_PORT}) ==="
          response=$(curl -s "${BACKEND_URL}/api/hello")
          echo "$response" | jq .
          # Message now includes build info, so use startswith check
          echo "$response" | jq -e '.message | startswith("hello from backend")'
          
          echo "=== Testing Greet Endpoint ==="
          response=$(curl -s "${BACKEND_URL}/api/greet/E2ETest")
          echo "$response" | jq .
          echo "$response" | jq -e '.message == "Hello, E2ETest!"'
          
          echo "=== Testing Get Greetings ==="
          response=$(curl -s "${BACKEND_URL}/api/greetings")
          echo "$response" | jq .
          echo "$response" | jq -e '.total > 0'
          
          echo "=== Testing User Greetings ==="
          response=$(curl -s "${BACKEND_URL}/api/greetings/E2ETest")
          echo "$response" | jq .
          echo "$response" | jq -e '.count > 0'
      
      - name: Test version metadata
        run: |
          # Build compose file list
          COMPOSE_FILES="${{ steps.detect-services.outputs.compose_files }}"
          
          # Get backend and frontend URLs (dynamic)
          BACKEND_SERVICES="${{ steps.detect-services.outputs.backend_services }}"
          FRONTEND_SERVICES="${{ steps.detect-services.outputs.frontend_services }}"
          
          if [ -n "$BACKEND_SERVICES" ]; then
            # Get first backend service (space-separated format)
            FIRST_BACKEND=$(echo "$BACKEND_SERVICES" | awk '{print $1}')
            
            # Extract port - handle both variable expansion and direct port formats
            BACKEND_PORT=$(docker compose $COMPOSE_FILES config 2>/dev/null | \
              grep -A 30 "^  ${FIRST_BACKEND}:" | \
              grep -E "^\s+-\s+.*:8000" | \
              head -1 | \
              sed -E 's/.*:([0-9]+):8000/\1/' || echo "8000")
            
            # Fallback: if port extraction failed, try alternative pattern
            if [ -z "$BACKEND_PORT" ] || [ "$BACKEND_PORT" = "8000" ]; then
              # Try to get port from actual running container
              BACKEND_PORT=$(docker compose $COMPOSE_FILES ps --format json 2>/dev/null | \
                jq -r ".[] | select(.Service == \"$FIRST_BACKEND\") | .Publishers[0].PublishedPort // empty" 2>/dev/null || echo "")
              if [ -z "$BACKEND_PORT" ]; then
                BACKEND_PORT="8000"  # Default fallback
                echo "::warning::Could not extract backend port, using default: $BACKEND_PORT"
              else
                echo "::notice::Extracted backend port from running container: $BACKEND_PORT"
              fi
            fi
            
            BACKEND_URL="http://localhost:${BACKEND_PORT}"
            
            echo "=== Verify Backend Version (${FIRST_BACKEND} on port ${BACKEND_PORT}) ==="
            response=$(curl -s "${BACKEND_URL}/version")
            echo "$response" | jq .
            echo "$response" | jq -e '.version == "${{ needs.prepare-build.outputs.version }}"'
            echo "$response" | jq -e '.commit == "${{ needs.prepare-build.outputs.commit }}"'
          fi
          
          if [ -n "$FRONTEND_SERVICES" ]; then
            # Get first frontend service (space-separated format)
            FIRST_FRONTEND=$(echo "$FRONTEND_SERVICES" | awk '{print $1}')
            
            # Extract port - handle both variable expansion and direct port formats
            FRONTEND_PORT=$(docker compose $COMPOSE_FILES config 2>/dev/null | \
              grep -A 30 "^  ${FIRST_FRONTEND}:" | \
              grep -E "^\s+-\s+.*:3000" | \
              head -1 | \
              sed -E 's/.*:([0-9]+):3000/\1/' || echo "3000")
            
            # Fallback: if port extraction failed, try alternative pattern
            if [ -z "$FRONTEND_PORT" ] || [ "$FRONTEND_PORT" = "3000" ]; then
              # Try to get port from actual running container
              FRONTEND_PORT=$(docker compose $COMPOSE_FILES ps --format json 2>/dev/null | \
                jq -r ".[] | select(.Service == \"$FIRST_FRONTEND\") | .Publishers[0].PublishedPort // empty" 2>/dev/null || echo "")
              if [ -z "$FRONTEND_PORT" ]; then
                FRONTEND_PORT="3000"  # Default fallback
                echo "::warning::Could not extract frontend port, using default: $FRONTEND_PORT"
              else
                echo "::notice::Extracted frontend port from running container: $FRONTEND_PORT"
              fi
            fi
            
            FRONTEND_URL="http://localhost:${FRONTEND_PORT}"
            
            echo "=== Verify Frontend Version (${FIRST_FRONTEND} on port ${FRONTEND_PORT}) ==="
            response=$(curl -s "${FRONTEND_URL}/version.json")
            echo "$response" | jq .
            echo "$response" | jq -e '.version == "${{ needs.prepare-build.outputs.version }}"'
          fi
      
      - name: Show service logs on failure
        if: failure()
        run: |
          # Build compose file list (same as detect-services step)
          COMPOSE_FILES="-f docker-compose.base.yml"
          for APP_COMPOSE in applications/*/docker-compose.yml; do
            if [ -f "$APP_COMPOSE" ]; then
              COMPOSE_FILES="$COMPOSE_FILES -f $APP_COMPOSE"
            fi
          done
          
          echo "=== Container Status ==="
          docker compose $COMPOSE_FILES ps -a || echo "Failed to get container status"
          
          echo -e "\n=== Container Health Details ==="
          ALL_SERVICES=$(docker compose $COMPOSE_FILES config --services 2>/dev/null || echo "")
          for service in $ALL_SERVICES; do
            echo "--- $service health ---"
            docker inspect --format="{{json .State.Health}}" "$service" 2>/dev/null | jq . || echo "No health info for $service"
          done
          
          echo -e "\n=== Full Docker Compose Logs ==="
          docker compose $COMPOSE_FILES logs --no-color || echo "Failed to get logs"
          
          echo -e "\n=== Service Container States ==="
          for service in $ALL_SERVICES; do
            echo "--- $service state ---"
            docker inspect "$service" 2>/dev/null | jq '.[0].State' || echo "Container $service not found"
          done
      
      - name: Stop services
        if: always()
        run: |
          # Build compose file list (same as detect-services step)
          COMPOSE_FILES="-f docker-compose.base.yml"
          for APP_COMPOSE in applications/*/docker-compose.yml; do
            if [ -f "$APP_COMPOSE" ]; then
              COMPOSE_FILES="$COMPOSE_FILES -f $APP_COMPOSE"
            fi
          done
          docker compose $COMPOSE_FILES down -v || echo "Failed to stop services (non-critical)"

  # ===========================================================================
  # Security Scanning
  # ===========================================================================
  
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [build-images, detect-changes, detect-app-images, filter-build-matrix]
    # We must use `always()` so this job's `if` condition is evaluated even if upstream jobs are skipped.
    if: |
      always() &&
      github.event_name != 'pull_request' &&
      (needs.detect-changes.outputs.backend-code == 'true' ||
       needs.detect-changes.outputs.frontend-code == 'true' ||
       startsWith(github.ref, 'refs/tags/v') ||
       github.event_name == 'workflow_dispatch') &&
      (needs.build-images.result == 'success' || needs.build-images.result == 'skipped') &&
      (needs.detect-app-images.result == 'success') &&
      (needs.filter-build-matrix.result == 'success')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Get images to scan
        id: get-images
        run: |
          BUILD_MATRIX='${{ needs.detect-app-images.outputs.matrix }}'
          FIRST_IMAGE=$(echo "$BUILD_MATRIX" | jq -r '.include[0].image_name // "ci-backend"')
          ALL_IMAGES=$(echo "$BUILD_MATRIX" | jq -r '.include[] | "\(.image_name)"' | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "first_image=$FIRST_IMAGE" >> $GITHUB_OUTPUT
          echo "all_images=$ALL_IMAGES" >> $GITHUB_OUTPUT
          echo "::notice::Will scan all images, uploading $FIRST_IMAGE to GitHub Security"
      
      - name: Run Trivy for primary image (GitHub Security upload)
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.29.0
        with:
          image-ref: 'ghcr.io/${{ github.repository_owner }}/${{ steps.get-images.outputs.first_image }}:latest'
          format: 'sarif'
          output: 'trivy-results-primary.sarif'
      
      - name: Upload Trivy results to GitHub Security
        continue-on-error: true
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: 'trivy-results-primary.sarif'
      
      - name: Run Trivy for all images (detailed reports)
        continue-on-error: true
        run: |
          BUILD_MATRIX='${{ needs.detect-app-images.outputs.matrix }}'
          for image_name in $(echo "$BUILD_MATRIX" | jq -r '.include[] | "\(.image_name)"'); do
            echo "::group::Trivy scan for $image_name"
            # Note: Using Trivy action would require a matrix, so we'll use docker run
            # For now, we'll just log that we would scan this image
            # Full scanning is done via the primary image upload above
            echo "Image: ghcr.io/${{ github.repository_owner }}/${image_name}:latest"
            echo "::notice::Full scan results available in GitHub Security (primary image) and artifacts"
            echo "::endgroup::"
          done
      
      - name: Upload Trivy results as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-security-reports
          path: trivy-results-*.sarif
          if-no-files-found: ignore
          retention-days: 30
      
      # Docker Scout - Advanced vulnerability analysis and recommendations
      - name: Login to Docker Hub (for Scout)
        if: github.event_name != 'pull_request'
        continue-on-error: true
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      
      - name: Docker Scout CVE Analysis
        continue-on-error: true
        run: |
          BUILD_MATRIX='${{ needs.detect-app-images.outputs.matrix }}'
          for image_name in $(echo "$BUILD_MATRIX" | jq -r '.include[] | "\(.image_name)"'); do
            echo "::group::Docker Scout CVE Analysis for $image_name"
            docker scout cves \
              --only-severity critical,high \
              "ghcr.io/${{ github.repository_owner }}/${image_name}:latest" || echo "::warning::Docker Scout failed for $image_name"
            echo "::endgroup::"
          done
      
      - name: Docker Scout Recommendations
        continue-on-error: true
        run: |
          BUILD_MATRIX='${{ needs.detect-app-images.outputs.matrix }}'
          for image_name in $(echo "$BUILD_MATRIX" | jq -r '.include[] | "\(.image_name)"'); do
            echo "::group::Docker Scout Recommendations for $image_name"
            docker scout recommendations \
              "ghcr.io/${{ github.repository_owner }}/${image_name}:latest" || echo "::warning::Docker Scout recommendations failed for $image_name"
            echo "::endgroup::"
          done

  # ===========================================================================
  # Release & Deployment
  # ===========================================================================
  
  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: [e2e-tests, prepare-build]
    if: startsWith(github.ref, 'refs/tags/v')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Generate changelog
        id: changelog
        run: |
          # Simple changelog generation
          echo "## What's Changed" > CHANGELOG.txt
          git log --pretty=format:"* %s" $(git describe --tags --abbrev=0 HEAD^)..HEAD >> CHANGELOG.txt
          cat CHANGELOG.txt
      
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          body_path: CHANGELOG.txt
          draft: false
          prerelease: false
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===========================================================================
  # Summary
  # ===========================================================================
  
  summary:
    name: Build Summary
    runs-on: ubuntu-latest
    needs: [e2e-tests, prepare-build, detect-changes, build-images, code-quality, backend-tests, frontend-tests, app-backend-tests, detect-app-images, filter-build-matrix, validate-dhall]
    if: always()
    
    steps:
      - name: Create summary
        run: |
          echo "## 🚀 Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version:** \`${{ needs.prepare-build.outputs.version }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ needs.prepare-build.outputs.commit }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** \`${{ needs.prepare-build.outputs.branch }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Build Date:** \`${{ needs.prepare-build.outputs.build_date }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          APP_CODE_CHANGED="${{ needs.detect-changes.outputs.app-code }}"
          IS_TAG="${{ startsWith(github.ref, 'refs/tags/v') }}"
          IS_MANUAL="${{ github.event_name == 'workflow_dispatch' }}"
          
          if [ "$APP_CODE_CHANGED" == "true" ] || [ "$IS_TAG" == "true" ] || [ "$IS_MANUAL" == "true" ]; then
            echo "### ✅ Application Code Changed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 📦 Images Built" >> $GITHUB_STEP_SUMMARY
            
            # Get images from filtered build matrix (what was actually built)
            # Use filtered matrix if available, otherwise fall back to full matrix
            FILTERED_MATRIX='${{ needs.filter-build-matrix.outputs.matrix }}'
            FULL_MATRIX='${{ needs.detect-app-images.outputs.matrix }}'
            VERSION='${{ needs.prepare-build.outputs.version }}'
            OWNER='${{ github.repository_owner }}'
            
            # Prefer filtered matrix (what was actually built), fall back to full matrix
            if [ -n "$FILTERED_MATRIX" ] && [ "$FILTERED_MATRIX" != "null" ] && [ "$FILTERED_MATRIX" != "{\"include\": []}" ]; then
              BUILD_MATRIX="$FILTERED_MATRIX"
            elif [ -n "$FULL_MATRIX" ] && [ "$FULL_MATRIX" != "null" ]; then
              BUILD_MATRIX="$FULL_MATRIX"
            else
              BUILD_MATRIX=""
            fi
            
            if [ -n "$BUILD_MATRIX" ] && [ "$BUILD_MATRIX" != "null" ]; then
              # Use jq to extract data, then construct markdown in bash to avoid escaping issues
              echo "$BUILD_MATRIX" | jq -r --arg version "$VERSION" --arg owner "$OWNER" '.include[] | "\($owner)|\(.image_name)|\($version)|\(.type)"' | while IFS='|' read -r owner_name image_name img_version img_type; do
                echo "- \`ghcr.io/${owner_name}/${image_name}:${img_version}\` (${img_type})" >> $GITHUB_STEP_SUMMARY
              done
            else
              # Fallback to shared images if matrix not available
              echo "- \`ghcr.io/${{ github.repository_owner }}/ci-backend:${{ needs.prepare-build.outputs.version }}\`" >> $GITHUB_STEP_SUMMARY
              echo "- \`ghcr.io/${{ github.repository_owner }}/ci-frontend:${{ needs.prepare-build.outputs.version }}\`" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "### ⏭️  Workflow Optimized" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Tests, builds, and scans were **skipped** because no application code changed." >> $GITHUB_STEP_SUMMARY
            echo "Only workflow/infrastructure files were modified in this commit." >> $GITHUB_STEP_SUMMARY
          fi
